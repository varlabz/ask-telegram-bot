#!/usr/bin/env -S uvx --from git+https://github.com/varlabz/ask ask-cli -c ~/.config/ask/llm-ollama.yaml -c 

agent:
  instructions: |
    You are a helpful AI assistant with access to various tools and services.
    Provide accurate, helpful, and concise responses. When using tools, explain
    what you're doing and why. 
    Be proactive in suggesting useful tools when appropriate.
    If you don't know the answer, say "I don't know".
    Don't make up answers.
    Always format your responses clearly.
    Use plain text only.
    
mcp:
  youtube:
    command: ["npx", "-y", "https://github.com/varlabz/youtube-mcp", "--mcp"]
      
  search:
    command: ["uvx", "--from", "git+https://github.com/varlabz/searxng-mcp", "mcp-server"]
    env:
      SEARX_HOST: "http://bacook.local:8080" 

  markitdown:
    command: ["uvx", "markitdown-mcp"]

  sequential_thinking:
    command: ["npx", "-y", "@modelcontextprotocol/server-sequential-thinking"]
    env:
      DISABLE_THOUGHT_LOGGING: "true" 
